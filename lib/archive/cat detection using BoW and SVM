import cv2
import joblib
import os
import csv
import numpy
import sklearn
from sklearn import svm
import time

corrupt=numpy.array([140, 152, 821, 2237, 2246, 2247, 2253, 2265, 2274, 2283, 2293, 2299, 6903, 6909]+[4,6,8])
corrupt=numpy.array(corrupt)-numpy.array([1]*len(corrupt))
with open("class.txt","r") as file:
    image_classes= file.read().split("\n")

image_classes=image_classes[0:len(image_classes)-1]
index=set(range(len(image_classes)))
index=index.difference(corrupt)
image_classes=[image_classes[i] for i in index]

folderPath='/Users/JPC/Documents/Columbia/2nd Semester/1. Applied Data Science/2. Homeworks/Project 3/images'
image_names = os.listdir(folderPath)
image_names = image_names[2:len(image_names)+1]
image_names=[image_names[i] for i in index]

total=2000
image_classes_train=image_classes[0:total]
image_classes_test=image_classes[total+2000:total+2000+800]
training_names=image_names[0:total]
testing_names=image_names[total+2000:total+2000+800]

image_paths = [os.path.join(folderPath, f) for f in training_names]
testing_paths=[os.path.join(folderPath, f) for f in testing_names]

# feature_det = cv2.FeatureDetector_create("SIFT")
feature_det = cv2.xfeatures2d.SIFT_create()


def preProcessImages(image_paths):
    descriptors= []
    for image_path in image_paths:
        im = cv2.imread(image_path)
        kpts = feature_det.detect(im)
        # kpts, des = descr_ext.compute(im, kpts)
        kpts, des = feature_det.compute(im, kpts)
        descriptors.append(des)
    return descriptors

start = time.time()
descriptors=preProcessImages(image_paths)
end = time.time()
print("Descriptors")
print((end - start)/60)


descriptors_none=[]
for i, j in enumerate(descriptors):
    if j == None:
        descriptors_none.append(i)

descriptors=[i for i in descriptors if i!= None]
image_classes_train=[image_classes_train[i] for i in range(total) if i not in descriptors_none]
image_paths=[image_paths[i] for i in range(total) if i not in descriptors_none]

def getImagedata(feature_det,bow_extract,path):
    im = cv2.imread(path)
    featureset = bow_extract.compute(im, feature_det.detect(im))
    return featureset

# def train(descriptors,image_classes_train,image_paths):  
flann_params = dict(algorithm = 1, trees = 5)     
matcher = cv2.FlannBasedMatcher(flann_params, {})
# bow_extract  =cv2.BOWImgDescriptorExtractor(descr_ext,matcher)
bow_extract  =cv2.BOWImgDescriptorExtractor(feature_det,matcher)
bow_train = cv2.BOWKMeansTrainer(20)
start = time.time()
for des in descriptors:
    bow_train.add(des)
descriptors=preProcessImages(image_paths)
end = time.time()
print("Vocabulary")
print((end - start)/60)

voc = bow_train.cluster()
bow_extract.setVocabulary( voc )
traindata = []  
start = time.time()
for imagepath in image_paths:
    featureset = getImagedata(feature_det,bow_extract,imagepath)
    traindata.extend(featureset)
end = time.time()
print("Extracting vocabulary")
print((end - start)/60)

clf=sklearn.svm.classes.LinearSVC()
# clf = LinearSVC()
clf.fit(traindata, numpy.array(image_classes_train))
joblib.dump((voc,clf), "imagereco.pkl", compress=3)

# model=train(descriptors,image_classes_train,image_paths)

# Accuracy Training data
prediction = clf.predict(traindata)
p=numpy.array(prediction)
c=numpy.array(image_classes_train)
print("Accuracy with training")
numpy.sum(p==c)/(len(prediction)*1.000)

voc, clf = joblib.load("imagereco.pkl")


# Accuracy Test data
prediction_test=[]
for imagepath in testing_paths:
    featureset = getImagedata(feature_det,bow_extract,imagepath)
    prediction_temp = clf.predict(featureset)
    if list(prediction_temp) ==['1']:
        prediction_test.append('1')
    else:
        prediction_test.append('0')
p=numpy.array(prediction_test)
c=numpy.array(image_classes_test)
print("Accuracy with training")
numpy.sum(p==c)/(len(prediction_test)*1.000)






